<h1>Data Engineering Pipeline</h1>
<h2>1 Einführung</h2>
In diesem Portfolio wird die Dateninfrastruktur für eine Machine Learning Anwendung geplant und umgesetzt. Geplant wird eine Batch-Prozessierung, die eine Menge an Rohdaten verarbeiten muss. Die Rohdaten sollen eingelesen und in die benötigte Form für die Machine Learning Anwendung gebracht werden. Nach dem Rohdaten prozessieren und aggregieren werden die Daten zur Weiter-verarbeitung bereitgestellt. Die Machine Learning Anwendung selbst ist nicht Teil des Portfolios.
Die Anforderungen an die Datenverarbeitung sind dabei die Robustheit, Skalierbarkeit und Wart-barkeit. Damit soll sichergestellt werden, dass die Batch-Prozessierung mit einer rapide wachsen-den Anzahl an Rohdaten umgehen kann und dabei verlässliche Ergebnisse liefert.
Die Machine Learning Anwendung läuft einmal im Quartal durch. Die Rohdaten müssen somit alle drei Monate bereitgestellt werden. Damit die Machine Learning Anwendung die aktuellsten Daten verarbeitet, werden die Daten kurz vorher aufbereitet.

<h2>2 Architektur</h2>
![image](https://github.com/Patten14/Data_Engineering/assets/126598504/07c543d2-6646-4e8c-a910-0d0f4b7dcb35)
Wie in der Abbildung oben gezeigt liegen die Rohdaten, sowie die Go-Applikation auf der lokalen Maschine und werden in ein Docker-Image gepackt. Das Docker-Image kann dann von jeder Hardware aus-geführt werden. Die Go-Applikation erstellt beim Start den S3-Bucket und lädt dort die Rohdaten, sowie das Python-Skript für den AWS Glue-Job hoch. Danach wird AWS Glue erstellt. Damit Glue laufen kann, braucht es eine eigene Datenbank. Danach wird ein Crawler erstellt, der die Daten aus dem S3-Bucket in die Glue-Datenbank schreibt. Der Glue-Job ist die eigentliche Aufgabe und kümmert sich um das Verarbeiten der Rohdaten. Für diese Aufgabe wird auch das Python-Skript auf dem S3-Bucket bereitgestellt. Damit der Glue-Job ausgeführt wird, benötigt es einen Trigger. Der Trigger wartet auf einen erfolgreichen Durchlauf des Crawlers und startet dann den Job. Die Komponenten Glue-Datenbank, Glue-Crawler, Glue-Job und Glue-Trigger werden von der Go-Applikation nacheinander erstellt und passend eingerichtet. Der Crawler sorgt mit einem Schedule, dass alle drei Monate der Crawler ausgeführt wird und danach der Trigger den Job anstoßt. Die verarbeiteten Daten werden wieder im S3-Bucket platziert und können dann von Quicksight abge-rufen werden. 
Die Vorteile der gewählten Architektur liegt bei der einfachen Gestaltung. Durch wenige Dienste, die verwendet werden, wird eine Komplexität vermieden. Eine geringe Komplexität trägt zu einer bes-seren Wartbarkeit bei und hilft bei dem Verständnis der Architektur und der gesamten Verarbeitung. Darüber hinaus ist der Administrationsaufwand geringer. Die einzelnen Dienste von AWS können über ein Infrastructure as Code (IaC) und der AWS CLI einfach verwaltet werden. Die IaC-Skripte sind bestens geeignet für eine Versionsverwaltung. 
Ein Nachteil sind die Kosten. Der S3 Speicher und AWS Glue sind immer aktiv und warten auf ih-ren Einsatz. Sie könnten im Vorfeld für jeden Prozessdurchlauf eingerichtet und gestartet werden. Die Hochfahrzeit müsste dafür in dem Prozess berücksichtigt werden. Außerdem werden nach dem Durchlauf alle Daten in der Cloud gelöscht. Die Machine Learning Anwendung muss die be-reitgestellten Daten entweder selbst zwischenspeichern oder es muss auf das Beenden der Anwen-dung gewartet werden, was wieder extra Aufwand bedeutet. Ein weiterer Nachteil ist das Speichern der Rohdaten. Diese könnten direkt in eine Datenbank geschrieben werden. Bei großen und vielen Rohdaten könnte so die Datenquelle parallel hochgeladen werden. Die begrenzende Größe ist hier-bei die Bandbreite des lokalen Computers.
Die Vorteile überwiegen für den Start und die Nachteile lassen sich zu einem späteren Zeitpunkt immer noch lösen.
