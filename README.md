<h1>Data Engineering Pipeline</h1>
<h2>1 Einführung</h2>
In diesem Portfolio wird die Dateninfrastruktur für eine Machine Learning Anwendung geplant und umgesetzt. Geplant wird eine Batch-Prozessierung, die eine Menge an Rohdaten verarbeiten muss. Die Rohdaten sollen eingelesen und in die benötigte Form für die Machine Learning Anwendung gebracht werden. Nach dem Rohdaten prozessieren und aggregieren werden die Daten zur Weiter-verarbeitung bereitgestellt. Die Machine Learning Anwendung selbst ist nicht Teil des Portfolios.<br>
Die Anforderungen an die Datenverarbeitung sind dabei die Robustheit, Skalierbarkeit und Wart-barkeit. Damit soll sichergestellt werden, dass die Batch-Prozessierung mit einer rapide wachsen-den Anzahl an Rohdaten umgehen kann und dabei verlässliche Ergebnisse liefert.<br>
Die Machine Learning Anwendung läuft einmal im Quartal durch. Die Rohdaten müssen somit alle drei Monate bereitgestellt werden. Damit die Machine Learning Anwendung die aktuellsten Daten verarbeitet, werden die Daten kurz vorher aufbereitet.<br>
<h2>2 Architektur</h2>
![Flowchart](https://github.com/Patten14/Data_Engineering/Assets/Flow_Chart.svg)<br>
Wie in der Abbildung oben gezeigt liegen die Rohdaten, sowie die Go-Applikation auf der lokalen Maschine und werden in ein Docker-Image gepackt. Das Docker-Image kann dann von jeder Hardware aus-geführt werden. Die Go-Applikation erstellt beim Start den S3-Bucket und lädt dort die Rohdaten, sowie das Python-Skript für den AWS Glue-Job hoch. Danach wird AWS Glue erstellt. Damit Glue laufen kann, braucht es eine eigene Datenbank. Danach wird ein Crawler erstellt, der die Daten aus dem S3-Bucket in die Glue-Datenbank schreibt. Der Glue-Job ist die eigentliche Aufgabe und kümmert sich um das Verarbeiten der Rohdaten. Für diese Aufgabe wird auch das Python-Skript auf dem S3-Bucket bereitgestellt. Damit der Glue-Job ausgeführt wird, benötigt es einen Trigger. Der Trigger wartet auf einen erfolgreichen Durchlauf des Crawlers und startet dann den Job. Die Komponenten Glue-Datenbank, Glue-Crawler, Glue-Job und Glue-Trigger werden von der Go-Applikation nacheinander erstellt und passend eingerichtet. Der Crawler sorgt mit einem Schedule, dass alle drei Monate der Crawler ausgeführt wird und danach der Trigger den Job anstoßt. Die verarbeiteten Daten werden wieder im S3-Bucket platziert und können dann von Quicksight abge-rufen werden.<br>
Die Vorteile der gewählten Architektur liegt bei der einfachen Gestaltung. Durch wenige Dienste, die verwendet werden, wird eine Komplexität vermieden. Eine geringe Komplexität trägt zu einer bes-seren Wartbarkeit bei und hilft bei dem Verständnis der Architektur und der gesamten Verarbeitung. Darüber hinaus ist der Administrationsaufwand geringer. Die einzelnen Dienste von AWS können über ein Infrastructure as Code (IaC) und der AWS CLI einfach verwaltet werden. Die IaC-Skripte sind bestens geeignet für eine Versionsverwaltung. <br>
Ein Nachteil sind die Kosten. Der S3 Speicher und AWS Glue sind immer aktiv und warten auf ih-ren Einsatz. Sie könnten im Vorfeld für jeden Prozessdurchlauf eingerichtet und gestartet werden. Die Hochfahrzeit müsste dafür in dem Prozess berücksichtigt werden. Außerdem werden nach dem Durchlauf alle Daten in der Cloud gelöscht. Die Machine Learning Anwendung muss die be-reitgestellten Daten entweder selbst zwischenspeichern oder es muss auf das Beenden der Anwen-dung gewartet werden, was wieder extra Aufwand bedeutet. Ein weiterer Nachteil ist das Speichern der Rohdaten. Diese könnten direkt in eine Datenbank geschrieben werden. Bei großen und vielen Rohdaten könnte so die Datenquelle parallel hochgeladen werden. Die begrenzende Größe ist hier-bei die Bandbreite des lokalen Computers.<br>
Die Vorteile überwiegen für den Start und die Nachteile lassen sich zu einem späteren Zeitpunkt immer noch lösen.<br>
<h2>3 Umsetzung</h2>
<h3>Datensatz</h3>
Der Rohdatensatz ist eine CSV-Datei. In ihr befinden sich Tupel von Automarken mit einem Datum- und Uhrzeitstempel. Insgesamt sind es 1.000.000 Einträge. Die Daten liegen im Repository unter /Data und werden von dort hochgeladen.<br>
<h3>Go-Applikation</h3>
Neben der AWS-SDK wird Viper verwendet. Viper ist ein Tool um global für eine Go-Applikation Variablen zu Verwalten.<br>
Der Einstiegspunkt liegt auf der ersten Ebene in der main.go Datei. Dort ist eine Main-Funktion, die zunächst Viper initialisiert und die .env Datei als Ressource einbindet. Danach wird der WorkflowS3 aufgerufen. In der Funktion wird der S3-Bucket erstellt und die data.csv sowie glueJob.py werden in den S3 geladen. Nach dem S3 ist Glue dran. In CreateGlue wird erst die Datenbank erstellt und danach der Crawler. Danach folgt der Job und zum Schluss der Trigger.<br>
In den Unterordnern /s3Bucket und /glue befinden sich die Funktionen für die Erstellung und Benut-zung. Der S3-Bucket kann über die Go-Applikation auch geleert und gelöscht werden. Für Glue kann der Job gestartet werden, allerdings muss dafür der Crawler durchgelaufen sein. Der Crawler wird nach dem Erstellen direkt mit gestartet, so werden die Daten dem Job schon bereitgestellt. Allerdings ist die Applikation schneller als der Crawler und der Job kann nicht direkt gestartet wer-den und muss für den direkt erstmaligen Lauf über die Website gestartet werden. Der Trigger kümmert sich in Zukunft um das automatisierte Starten des Jobs, allerdings funktioniert der Trigger in AWS nur, wenn das auslöse Event nicht manuell gestartet wurde. Da der Crawler manuell ge-startet wurde (von der Go-Anwendung) löst der Trigger den Job nicht aus.<br>
<h3>Scripts</h3>
In dem Ordner /Skripts liegt das Python-Skript für den Glue-Job. Das Skript wird im S3-Bucket abgelegt und beim Erstellen des Glue-Jobs auf das Skript verwiesen.<br>
<h3>Quicksight</h3>
In /Quicksight befindet sich das Manifest für die Quicksight Applikation. Das Manifest in eine JSON-Datei, in der der Pfad der Daten vermerkt ist. Zu dem Pfad muss noch angegeben werden, in welchem Format die Daten abgespeichert sind. Im Fall von unserem CSV-Format muss noch das Trennzeichen angegeben werden und ob eine Beschriftungszeile vorhanden ist. Das Manifest wird beim Erstellen der Quicksight Analyse eingelesen. Der Pfad zu den Daten muss dabei immer auf den Aktuellen angepasst werden. Es muss für jeden neuen Datensatz eine eigene Quicksight Analyse und damit ein eigenes Manifest geschrieben werden. Das im Repository hinterlegte Mani-fest ist damit ein Template.<br>
